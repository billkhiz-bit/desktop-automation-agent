# Choose one LLM provider and set its API key.
# Ollama requires no API key (runs locally).

# OPENAI_API_KEY=your_openai_api_key_here
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# GEMINI_API_KEY=your_gemini_api_key_here
